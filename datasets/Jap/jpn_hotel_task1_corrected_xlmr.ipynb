{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Japanese Hotel – DimASR (Subtask 1) using XLM‑RoBERTa\n",
    "This notebook trains an `xlm-roberta-base` regression model for Japanese hotel finance data.\n",
    "- Train: `jpn_hotel_train_alltasks.jsonl` (Quadruplet format)\n",
    "- Dev:   `jpn_hotel_dev_task1.jsonl`     (Aspect list)\n",
    "It outputs predictions in `pred_jpn_hotel.jsonl` ready for SemEval Subtask 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: False\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os, json, torch, torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import AutoTokenizer, AutoModel, DataCollatorWithPadding\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('CUDA available:', torch.cuda.is_available())\n",
    "\n",
    "TRAIN = 'jpn_hotel_train_alltasks.jsonl'\n",
    "DEV   = 'jpn_hotel_dev_task1.jsonl'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jpn_hotel_train_alltasks.jsonl -> 1600 records\n",
      "jpn_hotel_dev_task1.jsonl -> 200 records\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def read_jsonl(path):\n",
    "    data = []\n",
    "    with open(path, 'r', encoding='utf8') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line:\n",
    "                data.append(json.loads(line))\n",
    "    print(path, '->', len(data), 'records')\n",
    "    return data\n",
    "\n",
    "train_json = read_jsonl(TRAIN)\n",
    "dev_json   = read_jsonl(DEV)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN rows: 2846\n",
      "DEV rows: 284\n",
      "Train DF head:\n",
      "                   ID                                               Text  \\\n",
      "0  hotel_quad_train_1                               スタッフも親切でまた近いうちに伺いますね   \n",
      "1  hotel_quad_train_2  ちょっぴり残念だったのは、2泊目の朝食…2泊目は、品数少なく、固形燃料で、食べるものもなく、...   \n",
      "2  hotel_quad_train_2  ちょっぴり残念だったのは、2泊目の朝食…2泊目は、品数少なく、固形燃料で、食べるものもなく、...   \n",
      "3  hotel_quad_train_2  ちょっぴり残念だったのは、2泊目の朝食…2泊目は、品数少なく、固形燃料で、食べるものもなく、...   \n",
      "4  hotel_quad_train_3                      お弁当が以前と少し変わったようで、おかずが増えた気がします   \n",
      "\n",
      "  Aspect  valence  arousal  \n",
      "0   スタッフ     6.33     6.17  \n",
      "1     品数     3.50     5.38  \n",
      "2     朝食     3.00     5.67  \n",
      "3     朝食     2.62     5.88  \n",
      "4    おかず     6.75     5.62  \n",
      "\n",
      "Dev DF head:\n",
      "                        ID                                               Text  \\\n",
      "0  hotel26_aspect_va_dev_1                    個室の浴室は良かったものの、客室のトイレが古すぎて臭かったです   \n",
      "1  hotel26_aspect_va_dev_1                    個室の浴室は良かったものの、客室のトイレが古すぎて臭かったです   \n",
      "2  hotel26_aspect_va_dev_2  施設内、食事、サービスだけでなく、施設のスタッフの方、送迎の運転手の方、全てスタッフの皆さん...   \n",
      "3  hotel26_aspect_va_dev_3            浴場やサウナは満足しているが、25時ごろまで時間を延ばしてもらえればありがたい   \n",
      "4  hotel26_aspect_va_dev_3            浴場やサウナは満足しているが、25時ごろまで時間を延ばしてもらえればありがたい   \n",
      "\n",
      "       Aspect  \n",
      "0          浴室  \n",
      "1         トイレ  \n",
      "2  全てスタッフの皆さん  \n",
      "3          浴場  \n",
      "4         サウナ  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "def build_train_df(data):\n",
    "    rows = []\n",
    "    for ex in data:\n",
    "        tid = ex['ID']\n",
    "        text = ex['Text']\n",
    "        for q in ex.get('Quadruplet', []):\n",
    "            va = q.get('VA', None)\n",
    "            if not va:\n",
    "                continue\n",
    "            try:\n",
    "                v_str, a_str = va.split('#')\n",
    "                rows.append({\n",
    "                    'ID': tid,\n",
    "                    'Text': text,\n",
    "                    'Aspect': q['Aspect'],\n",
    "                    'valence': float(v_str),\n",
    "                    'arousal': float(a_str),\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print('Skipping invalid VA:', va, 'error:', e)\n",
    "                continue\n",
    "    print('TRAIN rows:', len(rows))\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "def build_dev_df(data):\n",
    "    rows = []\n",
    "    for ex in data:\n",
    "        tid = ex['ID']\n",
    "        text = ex['Text']\n",
    "        for asp in ex['Aspect']:\n",
    "            rows.append({\n",
    "                'ID': tid,\n",
    "                'Text': text,\n",
    "                'Aspect': asp\n",
    "            })\n",
    "    print('DEV rows:', len(rows))\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "train_df = build_train_df(train_json)\n",
    "dev_df   = build_dev_df(dev_json)\n",
    "\n",
    "print('Train DF head:')\n",
    "print(train_df.head())\n",
    "print('\\nDev DF head:')\n",
    "print(dev_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "MODEL = 'xlm-roberta-base'\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "\n",
    "def combine(text, aspect):\n",
    "    return f\"{text} [ASP] {aspect}\"\n",
    "\n",
    "class HotelDataset(Dataset):\n",
    "    def __init__(self, df, is_train=True):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.is_train = is_train\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        combined = combine(row['Text'], row['Aspect'])\n",
    "        enc = tokenizer(\n",
    "            combined,\n",
    "            truncation=True,\n",
    "            max_length=128,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        item = {k: v.squeeze(0) for k, v in enc.items()}\n",
    "        item['ID'] = row['ID']\n",
    "        item['Aspect'] = row['Aspect']\n",
    "        if self.is_train:\n",
    "            item['labels'] = torch.tensor(\n",
    "                [row['valence'], row['arousal']],\n",
    "                dtype=torch.float32\n",
    "            )\n",
    "        return item\n",
    "\n",
    "train_ds = HotelDataset(train_df, is_train=True)\n",
    "dev_ds   = HotelDataset(dev_df,   is_train=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train batches: 356\n",
      "Dev batches: 18\n"
     ]
    }
   ],
   "source": [
    "\n",
    "collator = DataCollatorWithPadding(tokenizer)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    ids = [x['ID'] for x in batch]\n",
    "    aspects = [x['Aspect'] for x in batch]\n",
    "    for x in batch:\n",
    "        x.pop('ID')\n",
    "        x.pop('Aspect')\n",
    "    padded = collator(batch)\n",
    "    padded['ID'] = ids\n",
    "    padded['Aspect'] = aspects\n",
    "    return padded\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=8, shuffle=True,  collate_fn=collate_fn)\n",
    "dev_loader   = DataLoader(dev_ds,   batch_size=16, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "print('Train batches:', len(train_loader))\n",
    "print('Dev batches:', len(dev_loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DimASRHotelModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.base = AutoModel.from_pretrained(MODEL)\n",
    "        hidden = self.base.config.hidden_size\n",
    "        self.reg = nn.Linear(hidden, 2)  # valence, arousal\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        out = self.base(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        cls = out.last_hidden_state[:, 0]\n",
    "        return self.reg(cls)\n",
    "\n",
    "model = DimASRHotelModel().to(device)\n",
    "opt = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
    "loss_fn = nn.MSELoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training for 4 epochs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "507d792d256e4d1c8f8fde51f4199ae5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/4:   0%|          | 0/356 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 average loss: 3.0058\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5739e218eba24fe0b8ed430e7ce3dbed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/4:   0%|          | 0/356 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 average loss: 0.6741\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53ff002996c3451f9286202d667c9882",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/4:   0%|          | 0/356 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 average loss: 0.4748\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af1088d674914c34a1efe3f3c6fa0c28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/4:   0%|          | 0/356 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 average loss: 0.4100\n"
     ]
    }
   ],
   "source": [
    "\n",
    "EPOCHS = 4\n",
    "print('Starting training for', EPOCHS, 'epochs...')\n",
    "\n",
    "for ep in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for batch in tqdm(train_loader, desc=f'Epoch {ep+1}/{EPOCHS}'):\n",
    "        ids  = batch['input_ids'].to(device)\n",
    "        mask = batch['attention_mask'].to(device)\n",
    "        y    = batch['labels'].to(device)\n",
    "\n",
    "        preds = model(ids, mask)\n",
    "        loss = loss_fn(preds, y)\n",
    "\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / max(1, len(train_loader))\n",
    "    print(f'Epoch {ep+1} average loss: {avg_loss:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running inference on dev set...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46e4a35a689543c4a3388d561812ee4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total predictions: 284\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('Running inference on dev set...')\n",
    "\n",
    "model.eval()\n",
    "preds = []\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(dev_loader, desc='Inference'):\n",
    "        ids  = batch['input_ids'].to(device)\n",
    "        mask = batch['attention_mask'].to(device)\n",
    "        logits = model(ids, mask).cpu().numpy()\n",
    "\n",
    "        for i, (ID, asp) in enumerate(zip(batch['ID'], batch['Aspect'])):\n",
    "            v, a = logits[i]\n",
    "            preds.append((ID, asp, f\"{v:.2f}#{a:.2f}\"))\n",
    "\n",
    "print('Total predictions:', len(preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved predictions to pred_jpn_hotel.jsonl\n",
      "Exists: True\n",
      "Size (bytes): 22763\n"
     ]
    }
   ],
   "source": [
    "\n",
    "OUT = 'pred_jpn_hotel.jsonl'\n",
    "sub = {}\n",
    "\n",
    "for ID, asp, va in preds:\n",
    "    sub.setdefault(ID, []).append({'Aspect': asp, 'VA': va})\n",
    "\n",
    "with open(OUT, 'w', encoding='utf8') as f:\n",
    "    for ex in dev_json:\n",
    "        rec = {\n",
    "            'ID': ex['ID'],\n",
    "            'Aspect_VA': sub.get(ex['ID'], [])\n",
    "        }\n",
    "        f.write(json.dumps(rec, ensure_ascii=False) + '\\n')\n",
    "\n",
    "print('Saved predictions to', OUT)\n",
    "print('Exists:', os.path.exists(OUT))\n",
    "print('Size (bytes):', os.path.getsize(OUT))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
