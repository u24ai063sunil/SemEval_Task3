{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DimABSA 2026 – Subtask 1 (DimASR)\n",
    "## Chinese Finance (zho_finance) – 4‑Epoch PyTorch Baseline\n",
    "\n",
    "This notebook trains a DistilBERT multilingual regression model for **DimASR** on the **Chinese Finance** dataset:\n",
    "\n",
    "- Train: `Chi_finance_train_task1.jsonl`\n",
    "- Dev:   `Chi_finance_dev_task1.jsonl`\n",
    "\n",
    "It outputs predictions in the required JSONL format for **Subtask 1** and saves them as:\n",
    "\n",
    "```text\n",
    "pred_zho_finance.jsonl\n",
    "```\n",
    "\n",
    "You can then place this file inside `subtask_1/` and zip it as `subtask_1.zip` for Codabench submission.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: False\n",
      "Working directory: c:\\SemEval_task3\\datasets\\Chi\n",
      "Files: ['Chi_finance_dev_task1.jsonl', 'Chi_finance_task1_notebook.ipynb', 'Chi_finance_train_task1.jsonl', 'Chi_laptop_dev_task1.jsonl', 'Chi_laptop_dev_task2.jsonl', 'Chi_laptop_dev_task3.jsonl', 'Chi_restaurant_dev_task1.jsonl', 'Chi_restaurant_dev_task2.jsonl', 'Chi_restaurant_dev_task3.jsonl']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os, json, torch, torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import AutoTokenizer, AutoModel, DataCollatorWithPadding\n",
    "\n",
    "print('CUDA available:', torch.cuda.is_available())\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print('Working directory:', os.getcwd())\n",
    "print('Files:', os.listdir())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chi_finance_train_task1.jsonl -> 1000 records\n",
      "Chi_finance_dev_task1.jsonl -> 200 records\n"
     ]
    }
   ],
   "source": [
    "\n",
    "TRAIN = 'Chi_finance_train_task1.jsonl'\n",
    "DEV   = 'Chi_finance_dev_task1.jsonl'\n",
    "\n",
    "def read_jsonl(path):\n",
    "    data = []\n",
    "    with open(path, 'r', encoding='utf8') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line:\n",
    "                data.append(json.loads(line))\n",
    "    print(f'{path} -> {len(data)} records')\n",
    "    return data\n",
    "\n",
    "train_json = read_jsonl(TRAIN)\n",
    "dev_json   = read_jsonl(DEV)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN rows: 2633\n",
      "DEV rows: 563\n",
      "Train DF head:\n",
      "             ID                                               Text  \\\n",
      "0  5880111:S010  人壽、證券及票券子公司之業務持續穩健成長，全年稅後淨利分別達13.64億元、7.42億元及5...   \n",
      "1  5880111:S010  人壽、證券及票券子公司之業務持續穩健成長，全年稅後淨利分別達13.64億元、7.42億元及5...   \n",
      "2  5880111:S010  人壽、證券及票券子公司之業務持續穩健成長，全年稅後淨利分別達13.64億元、7.42億元及5...   \n",
      "3  5880111:S010  人壽、證券及票券子公司之業務持續穩健成長，全年稅後淨利分別達13.64億元、7.42億元及5...   \n",
      "4  2365114:S011                              優質成長，營收、獲利、本業、業外同步提升。   \n",
      "\n",
      "              Aspect  valence  arousal  \n",
      "0             全年稅後淨利     6.17     5.33  \n",
      "1      人壽及證券子公司之稅後淨利     6.00     5.17  \n",
      "2  資產管理、創投及投信子公司稅後淨利     5.88     5.12  \n",
      "3     人壽、證券及票券子公司之業務     6.00     5.17  \n",
      "4                 營收     6.25     5.62  \n",
      "\n",
      "Dev DF head:\n",
      "             ID                                               Text     Aspect\n",
      "0  3481114:S057  因應智慧城市與戶外顯示需求的快速發展，推動多領域顯示應用面板的全面升級，本公司積極將Mini...       智慧城市\n",
      "1  3481114:S057  因應智慧城市與戶外顯示需求的快速發展，推動多領域顯示應用面板的全面升級，本公司積極將Mini...  多領域顯示應用面板\n",
      "2  3481114:S057  因應智慧城市與戶外顯示需求的快速發展，推動多領域顯示應用面板的全面升級，本公司積極將Mini...       傳統背光\n",
      "3  3481114:S057  因應智慧城市與戶外顯示需求的快速發展，推動多領域顯示應用面板的全面升級，本公司積極將Mini...     戶外顯示需求\n",
      "4  5880108:S075  本公司108年度發展重點將以創新金融服務、發揮共體綜效、善用資源價值、優化資本管理、提高海外...       資本管理\n"
     ]
    }
   ],
   "source": [
    "def build_train_df(data):\n",
    "    rows = []\n",
    "    for ex in data:\n",
    "        tid = ex[\"ID\"]\n",
    "        text = ex[\"Text\"]\n",
    "\n",
    "        for pair in ex.get(\"Aspect_VA\", []):\n",
    "            asp = pair[\"Aspect\"]\n",
    "            v, a = pair[\"VA\"].split(\"#\")\n",
    "\n",
    "            rows.append({\n",
    "                \"ID\": tid,\n",
    "                \"Text\": text,\n",
    "                \"Aspect\": asp,\n",
    "                \"valence\": float(v),\n",
    "                \"arousal\": float(a)\n",
    "            })\n",
    "\n",
    "    print(\"TRAIN rows:\", len(rows))\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "# Dev DF from Aspect list\n",
    "def build_dev_df(data):\n",
    "    rows = []\n",
    "    for ex in data:\n",
    "        tid = ex['ID']\n",
    "        text = ex['Text']\n",
    "        for asp in ex['Aspect']:\n",
    "            rows.append({\n",
    "                'ID': tid,\n",
    "                'Text': text,\n",
    "                'Aspect': asp,\n",
    "            })\n",
    "    print('DEV rows:', len(rows))\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "train_df = build_train_df(train_json)\n",
    "dev_df   = build_dev_df(dev_json)\n",
    "\n",
    "print('Train DF head:')\n",
    "print(train_df.head())\n",
    "print('\\nDev DF head:')\n",
    "print(dev_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "MODEL_NAME = 'distilbert-base-multilingual-cased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "def combine_text(text, aspect):\n",
    "    return f\"{text} [ASP] {aspect}\"\n",
    "\n",
    "class DimASRDataset(Dataset):\n",
    "    def __init__(self, df, is_train=True):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.is_train = is_train\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        combined = combine_text(row['Text'], row['Aspect'])\n",
    "        enc = tokenizer(\n",
    "            combined,\n",
    "            truncation=True,\n",
    "            max_length=128,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        item = {k: v.squeeze(0) for k, v in enc.items()}\n",
    "        item['ID'] = row['ID']\n",
    "        item['Aspect'] = row['Aspect']\n",
    "        if self.is_train:\n",
    "            item['labels'] = torch.tensor(\n",
    "                [row['valence'], row['arousal']],\n",
    "                dtype=torch.float32\n",
    "            )\n",
    "        return item\n",
    "\n",
    "train_ds = DimASRDataset(train_df, is_train=True)\n",
    "dev_ds   = DimASRDataset(dev_df,   is_train=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train batches: 330\n",
      "Dev batches: 36\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "collator = DataCollatorWithPadding(tokenizer)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    ids = [x['ID'] for x in batch]\n",
    "    aspects = [x['Aspect'] for x in batch]\n",
    "    for x in batch:\n",
    "        x.pop('ID')\n",
    "        x.pop('Aspect')\n",
    "    padded = collator(batch)\n",
    "    padded['ID'] = ids\n",
    "    padded['Aspect'] = aspects\n",
    "    return padded\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=8, shuffle=True,  collate_fn=collate_fn)\n",
    "dev_loader   = DataLoader(dev_ds,   batch_size=16, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "print('Train batches:', len(train_loader))\n",
    "print('Dev batches:', len(dev_loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "552266daa240405aab1ed75022bd2896",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/542M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\choud\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\choud\\.cache\\huggingface\\hub\\models--distilbert-base-multilingual-cased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class DimASRModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.base = AutoModel.from_pretrained(MODEL_NAME)\n",
    "        self.reg  = nn.Linear(768, 2)  # valence, arousal\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        out = self.base(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        cls = out.last_hidden_state[:, 0]\n",
    "        return self.reg(cls)\n",
    "\n",
    "model = DimASRModel().to(device)\n",
    "opt = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
    "loss_fn = nn.MSELoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training for 4 epochs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3da2bd487c164b3787d9a5088232eb51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/4:   0%|          | 0/330 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 average loss: 1.0080\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd3420d752464ab99d4d2bd5dc0efb75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/4:   0%|          | 0/330 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 average loss: 0.2055\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "555e846e1c4e4327837c1cbda48f2444",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/4:   0%|          | 0/330 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 average loss: 0.1711\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "834f3ea84c60405d853de19ffe541222",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/4:   0%|          | 0/330 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 average loss: 0.1292\n"
     ]
    }
   ],
   "source": [
    "\n",
    "EPOCHS = 4\n",
    "print('Starting training for', EPOCHS, 'epochs...')\n",
    "\n",
    "for ep in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for batch in tqdm(train_loader, desc=f'Epoch {ep+1}/{EPOCHS}'):\n",
    "        ids  = batch['input_ids'].to(device)\n",
    "        mask = batch['attention_mask'].to(device)\n",
    "        y    = batch['labels'].to(device)\n",
    "\n",
    "        preds = model(ids, mask)\n",
    "        loss = loss_fn(preds, y)\n",
    "\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / max(1, len(train_loader))\n",
    "    print(f'Epoch {ep+1} average loss: {avg_loss:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running inference on dev set...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "527018197bb64d28b5b6a430a97cb0e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total predictions: 563\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('Running inference on dev set...')\n",
    "\n",
    "model.eval()\n",
    "preds = []\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(dev_loader, desc='Inference'):\n",
    "        ids  = batch['input_ids'].to(device)\n",
    "        mask = batch['attention_mask'].to(device)\n",
    "        logits = model(ids, mask).cpu().numpy()\n",
    "\n",
    "        for i, (ID, asp) in enumerate(zip(batch['ID'], batch['Aspect'])):\n",
    "            v, a = logits[i]\n",
    "            preds.append((ID, asp, f\"{v:.2f}#{a:.2f}\"))\n",
    "\n",
    "print('Total predictions:', len(preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved predictions to pred_zho_finance.jsonl\n",
      "Exists: True\n",
      "Size (bytes): 35433\n"
     ]
    }
   ],
   "source": [
    "\n",
    "OUT = 'pred_zho_finance.jsonl'\n",
    "\n",
    "sub = {}\n",
    "for ID, asp, va in preds:\n",
    "    sub.setdefault(ID, []).append({'Aspect': asp, 'VA': va})\n",
    "\n",
    "with open(OUT, 'w', encoding='utf8') as f:\n",
    "    for ex in dev_json:\n",
    "        rec = {\n",
    "            'ID': ex['ID'],\n",
    "            'Aspect_VA': sub.get(ex['ID'], [])\n",
    "        }\n",
    "        f.write(json.dumps(rec, ensure_ascii=False) + '\\n')\n",
    "\n",
    "print('Saved predictions to', OUT)\n",
    "print('Exists:', os.path.exists(OUT))\n",
    "print('Size (bytes):', os.path.getsize(OUT))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
