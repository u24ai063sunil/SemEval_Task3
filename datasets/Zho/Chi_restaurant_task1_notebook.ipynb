{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DimABSA 2026 – Subtask 1 (DimASR)\n",
    "## Chinese Restaurant (zho_restaurant) – 4-Epoch PyTorch Baseline\n",
    "\n",
    "This notebook trains a multilingual DistilBERT regression model for **DimASR** on the **Chinese Restaurant** dataset:\n",
    "\n",
    "- Train: `Chi_restaurant_train_alltasks.jsonl`  (Quadruplet format)\n",
    "- Dev:   `Chi_restaurant_dev_task1.jsonl`      (Aspect list format)\n",
    "\n",
    "It outputs predictions in the required JSONL format for **Subtask 1** and saves them as:\n",
    "\n",
    "```text\n",
    "pred_zho_restaurant.jsonl\n",
    "```\n",
    "\n",
    "Place this file inside `subtask_1/` as `pred_zho_restaurant.jsonl` for Codabench submission.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: False\n",
      "Working directory: c:\\SemEval_task3\\datasets\\Chi\n",
      "Files: ['Chi_finance_dev_task1.jsonl', 'Chi_finance_task1_notebook.ipynb', 'Chi_finance_train_task1.jsonl', 'Chi_laptop_dev_task1.jsonl', 'Chi_laptop_dev_task2.jsonl', 'Chi_laptop_dev_task3.jsonl', 'Chi_laptop_task1_notebook.ipynb', 'Chi_laptop_train_alltasks.jsonl', 'Chi_restaurant_dev_task1.jsonl', 'Chi_restaurant_dev_task2.jsonl', 'Chi_restaurant_dev_task3.jsonl', 'Chi_restaurant_task1_notebook.ipynb', 'Chi_restaurant_train_alltasks.jsonl']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os, json, torch, torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import AutoTokenizer, AutoModel, DataCollatorWithPadding\n",
    "\n",
    "print('CUDA available:', torch.cuda.is_available())\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print('Working directory:', os.getcwd())\n",
    "print('Files:', os.listdir())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chi_restaurant_train_alltasks.jsonl -> 6050 records\n",
      "Chi_restaurant_dev_task1.jsonl -> 225 records\n"
     ]
    }
   ],
   "source": [
    "\n",
    "TRAIN = 'Chi_restaurant_train_alltasks.jsonl'\n",
    "DEV   = 'Chi_restaurant_dev_task1.jsonl'\n",
    "\n",
    "def read_jsonl(path):\n",
    "    data = []\n",
    "    with open(path, 'r', encoding='utf8') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line:\n",
    "                data.append(json.loads(line))\n",
    "    print(f'{path} -> {len(data)} records')\n",
    "    return data\n",
    "\n",
    "train_json = read_jsonl(TRAIN)\n",
    "dev_json   = read_jsonl(DEV)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN rows: 8523\n",
      "DEV rows: 416\n",
      "Train DF head:\n",
      "           ID            Text Aspect  valence  arousal\n",
      "0  R0283:S003        肉粿沒有很焦脆。     肉粿     4.00     5.00\n",
      "1  R0283:S004  肉粿每一塊都好脆好恰好喜歡。     肉粿     6.25     6.00\n",
      "2  R0283:S004  肉粿每一塊都好脆好恰好喜歡。     肉粿     6.12     6.00\n",
      "3  R0283:S004  肉粿每一塊都好脆好恰好喜歡。     肉粿     6.62     6.62\n",
      "4  R0284:S012         口感有點微妙。     口感     4.75     4.75\n",
      "\n",
      "Dev DF head:\n",
      "            ID                                               Text Aspect\n",
      "0   R9340:S003          紅醬海鮮pizza $320這個pizza真的可以算是我看過賣像最差的pizza。     賣像\n",
      "1  R10003:S007  菜飯裡有青江菜和香腸，從白飯的顏色就可看出青菜的菜香和香腸的油脂都有煮進去，雖然味道較清淡，...     味道\n",
      "2  R10003:S007  菜飯裡有青江菜和香腸，從白飯的顏色就可看出青菜的菜香和香腸的油脂都有煮進去，雖然味道較清淡，...   客家小炒\n",
      "3   R7910:S000  記得年輕的時候來吃過，現在變的比較精緻小巧，整體用餐環境算乾淨，小菜選擇也不少，沒有紙寫帳單...   用餐環境\n",
      "4   R7910:S000  記得年輕的時候來吃過，現在變的比較精緻小巧，整體用餐環境算乾淨，小菜選擇也不少，沒有紙寫帳單...   小菜選擇\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train DF from Quadruplet format\n",
    "def build_train_df(data):\n",
    "    rows = []\n",
    "    for ex in data:\n",
    "        tid = ex['ID']\n",
    "        text = ex['Text']\n",
    "        for q in ex.get('Quadruplet', []):\n",
    "            try:\n",
    "                v_str, a_str = q['VA'].split('#')\n",
    "                rows.append({\n",
    "                    'ID': tid,\n",
    "                    'Text': text,\n",
    "                    'Aspect': q['Aspect'],\n",
    "                    'valence': float(v_str),\n",
    "                    'arousal': float(a_str),\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print('Skipping invalid VA in train:', q.get('VA'), 'error:', e)\n",
    "    print('TRAIN rows:', len(rows))\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# Dev DF from Aspect list\n",
    "def build_dev_df(data):\n",
    "    rows = []\n",
    "    for ex in data:\n",
    "        tid = ex['ID']\n",
    "        text = ex['Text']\n",
    "        for asp in ex['Aspect']:\n",
    "            rows.append({\n",
    "                'ID': tid,\n",
    "                'Text': text,\n",
    "                'Aspect': asp,\n",
    "            })\n",
    "    print('DEV rows:', len(rows))\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "train_df = build_train_df(train_json)\n",
    "dev_df   = build_dev_df(dev_json)\n",
    "\n",
    "print('Train DF head:')\n",
    "print(train_df.head())\n",
    "print('\\nDev DF head:')\n",
    "print(dev_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "MODEL_NAME = 'distilbert-base-multilingual-cased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "def combine_text(text, aspect):\n",
    "    return f\"{text} [ASP] {aspect}\"\n",
    "\n",
    "class DimASRDataset(Dataset):\n",
    "    def __init__(self, df, is_train=True):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.is_train = is_train\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        combined = combine_text(row['Text'], row['Aspect'])\n",
    "        enc = tokenizer(\n",
    "            combined,\n",
    "            truncation=True,\n",
    "            max_length=128,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        item = {k: v.squeeze(0) for k, v in enc.items()}\n",
    "        item['ID'] = row['ID']\n",
    "        item['Aspect'] = row['Aspect']\n",
    "        if self.is_train:\n",
    "            item['labels'] = torch.tensor(\n",
    "                [row['valence'], row['arousal']],\n",
    "                dtype=torch.float32\n",
    "            )\n",
    "        return item\n",
    "\n",
    "train_ds = DimASRDataset(train_df, is_train=True)\n",
    "dev_ds   = DimASRDataset(dev_df,   is_train=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train batches: 1066\n",
      "Dev batches: 26\n"
     ]
    }
   ],
   "source": [
    "\n",
    "collator = DataCollatorWithPadding(tokenizer)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    ids = [x['ID'] for x in batch]\n",
    "    aspects = [x['Aspect'] for x in batch]\n",
    "    for x in batch:\n",
    "        x.pop('ID')\n",
    "        x.pop('Aspect')\n",
    "    padded = collator(batch)\n",
    "    padded['ID'] = ids\n",
    "    padded['Aspect'] = aspects\n",
    "    return padded\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=8, shuffle=True,  collate_fn=collate_fn)\n",
    "dev_loader   = DataLoader(dev_ds,   batch_size=16, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "print('Train batches:', len(train_loader))\n",
    "print('Dev batches:', len(dev_loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DimASRModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.base = AutoModel.from_pretrained(MODEL_NAME)\n",
    "        self.reg  = nn.Linear(768, 2)  # valence, arousal\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        out = self.base(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        cls = out.last_hidden_state[:, 0]\n",
    "        return self.reg(cls)\n",
    "\n",
    "model = DimASRModel().to(device)\n",
    "opt = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
    "loss_fn = nn.MSELoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training for 4 epochs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a26cce0e12404ae18609fcd559f6cfdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/4:   0%|          | 0/1066 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 average loss: 0.7768\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e8945695f2a4d5ea658843efa600edd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/4:   0%|          | 0/1066 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 average loss: 0.2707\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f10ee6e40ea74ee5afeb33245e2640c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/4:   0%|          | 0/1066 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 average loss: 0.2064\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33926b62b22c44e4b0119d7e046c679d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/4:   0%|          | 0/1066 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 average loss: 0.1749\n"
     ]
    }
   ],
   "source": [
    "\n",
    "EPOCHS = 4\n",
    "print('Starting training for', EPOCHS, 'epochs...')\n",
    "\n",
    "for ep in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for batch in tqdm(train_loader, desc=f'Epoch {ep+1}/{EPOCHS}'):\n",
    "        ids  = batch['input_ids'].to(device)\n",
    "        mask = batch['attention_mask'].to(device)\n",
    "        y    = batch['labels'].to(device)\n",
    "\n",
    "        preds = model(ids, mask)\n",
    "        loss = loss_fn(preds, y)\n",
    "\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / max(1, len(train_loader))\n",
    "    print(f'Epoch {ep+1} average loss: {avg_loss:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running inference on dev set...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "733ea83bd6a24cadab1570d6ecd12ba8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/26 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total predictions: 416\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('Running inference on dev set...')\n",
    "\n",
    "model.eval()\n",
    "preds = []\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(dev_loader, desc='Inference'):\n",
    "        ids  = batch['input_ids'].to(device)\n",
    "        mask = batch['attention_mask'].to(device)\n",
    "        logits = model(ids, mask).cpu().numpy()\n",
    "\n",
    "        for i, (ID, asp) in enumerate(zip(batch['ID'], batch['Aspect'])):\n",
    "            v, a = logits[i]\n",
    "            preds.append((ID, asp, f\"{v:.2f}#{a:.2f}\"))\n",
    "\n",
    "print('Total predictions:', len(preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved predictions to pred_zho_restaurant.jsonl\n",
      "Exists: True\n",
      "Size (bytes): 26552\n"
     ]
    }
   ],
   "source": [
    "\n",
    "OUT = 'pred_zho_restaurant.jsonl'\n",
    "\n",
    "sub = {}\n",
    "for ID, asp, va in preds:\n",
    "    sub.setdefault(ID, []).append({'Aspect': asp, 'VA': va})\n",
    "\n",
    "with open(OUT, 'w', encoding='utf8') as f:\n",
    "    for ex in dev_json:\n",
    "        rec = {\n",
    "            'ID': ex['ID'],\n",
    "            'Aspect_VA': sub.get(ex['ID'], [])\n",
    "        }\n",
    "        f.write(json.dumps(rec, ensure_ascii=False) + '\\n')\n",
    "\n",
    "print('Saved predictions to', OUT)\n",
    "print('Exists:', os.path.exists(OUT))\n",
    "print('Size (bytes):', os.path.getsize(OUT))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
