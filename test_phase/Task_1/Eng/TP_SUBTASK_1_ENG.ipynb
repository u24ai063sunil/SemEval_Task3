{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "c2riE5ccQexn"
      },
      "outputs": [],
      "source": [
        "!pip install -q transformers torch scikit-learn tqdm emoji\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import re\n",
        "import unicodedata\n",
        "import emoji\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n"
      ],
      "metadata": {
        "id": "_ZNrB8Jlbat7"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN_PATH = \"/content/eng_restaurant_train_alltasks.jsonl\"\n",
        "TEST_PATH  = \"/content/eng_restaurant_test_task1.jsonl\"\n",
        "\n",
        "def load_jsonl(path):\n",
        "    data = []\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "        for line in f:\n",
        "            data.append(json.loads(line))\n",
        "    return data\n",
        "\n",
        "train_raw = load_jsonl(TRAIN_PATH)\n",
        "test_raw  = load_jsonl(TEST_PATH)\n",
        "\n",
        "print(\"Train reviews:\", len(train_raw))\n",
        "print(\"Test reviews :\", len(test_raw))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "whPSvwf3bgZr",
        "outputId": "3a96d5ad-f426-4d39-aeb9-c58fb7c69389"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train reviews: 2284\n",
            "Test reviews : 1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_text(text):\n",
        "    text = unicodedata.normalize(\"NFKC\", text)\n",
        "    text = text.replace(\"’\", \"'\").replace(\"“\", '\"').replace(\"”\", '\"')\n",
        "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
        "    return text\n",
        "\n",
        "def remove_urls_html(text):\n",
        "    text = re.sub(r\"http\\S+|www\\S+\", \"\", text)\n",
        "    text = re.sub(r\"<.*?>\", \"\", text)\n",
        "    return text\n",
        "\n",
        "def handle_emojis(text):\n",
        "    return emoji.demojize(text, delimiters=(\" \", \" \"))\n",
        "\n",
        "def clip_va(v, a):\n",
        "    v = min(max(v, 1.0), 9.0)\n",
        "    a = min(max(a, 1.0), 9.0)\n",
        "    return round(v, 2), round(a, 2)\n"
      ],
      "metadata": {
        "id": "_t4BKcf6bobO"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_train(data):\n",
        "    rows = []\n",
        "    for item in data:\n",
        "        if \"Quadruplet\" not in item:\n",
        "            continue\n",
        "\n",
        "        text = handle_emojis(remove_urls_html(normalize_text(item[\"Text\"])))\n",
        "\n",
        "        for quad in item[\"Quadruplet\"]:\n",
        "            aspect = quad[\"Aspect\"]\n",
        "            if aspect == \"NULL\":\n",
        "                continue\n",
        "\n",
        "            v, a = map(float, quad[\"VA\"].split(\"#\"))\n",
        "            v, a = clip_va(v, a)\n",
        "\n",
        "            rows.append({\n",
        "                \"text\": text,\n",
        "                \"aspect\": aspect.strip(),\n",
        "                \"valence\": v,\n",
        "                \"arousal\": a\n",
        "            })\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "def preprocess_test(data):\n",
        "    rows = []\n",
        "    for item in data:\n",
        "        if \"Aspect\" not in item:\n",
        "            continue\n",
        "\n",
        "        text = handle_emojis(remove_urls_html(normalize_text(item[\"Text\"])))\n",
        "\n",
        "        for asp in item[\"Aspect\"]:\n",
        "            rows.append({\n",
        "                \"id\": item[\"ID\"],\n",
        "                \"text\": text,\n",
        "                \"aspect\": asp.strip()\n",
        "            })\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "train_df = preprocess_train(train_raw)\n",
        "test_df  = preprocess_test(test_raw)\n",
        "\n",
        "print(\"Train aspect samples:\", len(train_df))\n",
        "print(\"Test aspect samples :\", len(test_df))\n",
        "\n",
        "train_df.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        },
        "id": "5Mw9Dz2DbrIA",
        "outputId": "f1f44732-f435-4156-a97c-a8ecec9dcffb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train aspect samples: 2779\n",
            "Test aspect samples : 1504\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text               aspect  \\\n",
              "0  their sake list was extensive , but we were lo...            sake list   \n",
              "1  the spicy tuna roll was unusually good and the...      spicy tuna roll   \n",
              "2  the spicy tuna roll was unusually good and the...  rock shrimp tempura   \n",
              "3                             we love th pink pony .            pink pony   \n",
              "4  this place has got to be the best japanese res...                place   \n",
              "\n",
              "   valence  arousal  \n",
              "0     7.83     8.00  \n",
              "1     7.50     7.62  \n",
              "2     8.25     8.38  \n",
              "3     7.17     7.00  \n",
              "4     7.88     8.12  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5f329df7-0d85-4164-8579-77edfcdb10ea\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>aspect</th>\n",
              "      <th>valence</th>\n",
              "      <th>arousal</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>their sake list was extensive , but we were lo...</td>\n",
              "      <td>sake list</td>\n",
              "      <td>7.83</td>\n",
              "      <td>8.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>the spicy tuna roll was unusually good and the...</td>\n",
              "      <td>spicy tuna roll</td>\n",
              "      <td>7.50</td>\n",
              "      <td>7.62</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>the spicy tuna roll was unusually good and the...</td>\n",
              "      <td>rock shrimp tempura</td>\n",
              "      <td>8.25</td>\n",
              "      <td>8.38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>we love th pink pony .</td>\n",
              "      <td>pink pony</td>\n",
              "      <td>7.17</td>\n",
              "      <td>7.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>this place has got to be the best japanese res...</td>\n",
              "      <td>place</td>\n",
              "      <td>7.88</td>\n",
              "      <td>8.12</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5f329df7-0d85-4164-8579-77edfcdb10ea')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5f329df7-0d85-4164-8579-77edfcdb10ea button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5f329df7-0d85-4164-8579-77edfcdb10ea');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_df",
              "summary": "{\n  \"name\": \"train_df\",\n  \"rows\": 2779,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1646,\n        \"samples\": [\n          \"the staff is no nonsense .\",\n          \"price is high but the food is good , so i would come back again .\",\n          \"the salads are delicious , both refreshing and very spicy .\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"aspect\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 874,\n        \"samples\": [\n          \"chinese style indian food\",\n          \"table\",\n          \"leon\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"valence\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.8194734408961648,\n        \"min\": 1.0,\n        \"max\": 9.0,\n        \"num_unique_values\": 127,\n        \"samples\": [\n          5.0,\n          6.3,\n          2.88\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"arousal\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0627863767355923,\n        \"min\": 3.83,\n        \"max\": 9.0,\n        \"num_unique_values\": 86,\n        \"samples\": [\n          6.9,\n          8.0,\n          6.4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df, temp_df = train_test_split(\n",
        "    train_df, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "val_df, test_internal_df = train_test_split(\n",
        "    temp_df, test_size=0.5, random_state=42\n",
        ")\n",
        "\n",
        "print(\"Train:\", len(train_df))\n",
        "print(\"Val  :\", len(val_df))\n",
        "print(\"Test :\", len(test_internal_df))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mQaCcqDfbt4i",
        "outputId": "f0afc839-080b-4aaf-eed8-2b8659337268"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 2223\n",
            "Val  : 278\n",
            "Test : 278\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_NAME = \"roberta-base\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "class AspectVADataset(Dataset):\n",
        "    def __init__(self, df, train=True):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.train = train\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "\n",
        "        enc = tokenizer(\n",
        "            row[\"text\"],\n",
        "            row[\"aspect\"],\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            max_length=128,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "\n",
        "        item = {\n",
        "            \"input_ids\": enc[\"input_ids\"].squeeze(0),\n",
        "            \"attention_mask\": enc[\"attention_mask\"].squeeze(0)\n",
        "        }\n",
        "\n",
        "        if self.train:\n",
        "            item[\"labels\"] = torch.tensor(\n",
        "                [row[\"valence\"], row[\"arousal\"]],\n",
        "                dtype=torch.float\n",
        "            )\n",
        "        return item\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ne0q2qRRby8F",
        "outputId": "856a68ba-6893-43a1-f35e-8c24094bf7a5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(\n",
        "    AspectVADataset(train_df, train=True),\n",
        "    batch_size=16,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    AspectVADataset(val_df, train=True),\n",
        "    batch_size=16\n",
        ")\n",
        "\n",
        "test_internal_loader = DataLoader(\n",
        "    AspectVADataset(test_internal_df, train=True),\n",
        "    batch_size=16\n",
        ")\n"
      ],
      "metadata": {
        "id": "4UTeRzzib2Od"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RobertaForVA(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.roberta = AutoModel.from_pretrained(MODEL_NAME)\n",
        "        self.regressor = torch.nn.Linear(768, 2)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.roberta(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask\n",
        "        )\n",
        "        pooled = outputs.last_hidden_state[:, 0, :]\n",
        "        return self.regressor(pooled)\n"
      ],
      "metadata": {
        "id": "OgBZHQDab6cT"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = RobertaForVA().to(device)\n",
        "\n",
        "optimizer = torch.optim.AdamW(\n",
        "    model.parameters(),\n",
        "    lr=2e-5,\n",
        "    weight_decay=0.01\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TaM3epA_b9EO",
        "outputId": "7aec5f6e-6703-4a31-b371-7d5561de8388"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def rmse_va(y_true, y_pred):\n",
        "    squared_diff = (y_pred - y_true) ** 2\n",
        "    return np.sqrt(squared_diff.sum(axis=1).mean())\n"
      ],
      "metadata": {
        "id": "okwg7sDib_j4"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_val_rmse = float(\"inf\")\n",
        "patience = 2\n",
        "patience_counter = 0\n",
        "\n",
        "MAX_EPOCHS = 10\n",
        "\n",
        "for epoch in range(MAX_EPOCHS):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for batch in tqdm(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        input_ids = batch[\"input_ids\"].to(device)\n",
        "        attention_mask = batch[\"attention_mask\"].to(device)\n",
        "        labels = batch[\"labels\"].to(device)\n",
        "\n",
        "        preds = model(input_ids, attention_mask)\n",
        "        loss = torch.nn.functional.smooth_l1_loss(preds, labels)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    model.eval()\n",
        "    val_preds, val_golds = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "            input_ids = batch[\"input_ids\"].to(device)\n",
        "            attention_mask = batch[\"attention_mask\"].to(device)\n",
        "            labels = batch[\"labels\"].to(device)\n",
        "\n",
        "            preds = model(input_ids, attention_mask)\n",
        "            val_preds.append(preds.cpu().numpy())\n",
        "            val_golds.append(labels.cpu().numpy())\n",
        "\n",
        "    val_preds = np.vstack(val_preds)\n",
        "    val_golds = np.vstack(val_golds)\n",
        "\n",
        "    val_rmse = rmse_va(val_golds, val_preds)\n",
        "\n",
        "    print(\n",
        "        f\"Epoch {epoch+1} | \"\n",
        "        f\"Train Loss: {total_loss/len(train_loader):.4f} | \"\n",
        "        f\"Val RMSE_VA: {val_rmse:.4f}\"\n",
        "    )\n",
        "\n",
        "    if val_rmse < best_val_rmse:\n",
        "        best_val_rmse = val_rmse\n",
        "        patience_counter = 0\n",
        "        torch.save(model.state_dict(), \"best_roberta_va.pt\")\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "        if patience_counter >= patience:\n",
        "            print(\"Early stopping triggered\")\n",
        "            break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zhFGeQgVcCf2",
        "outputId": "194e6ffb-527d-4a5f-9b7b-48f79a86560b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 139/139 [01:05<00:00,  2.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 | Train Loss: 1.2944 | Val RMSE_VA: 2.1638\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 139/139 [00:51<00:00,  2.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 | Train Loss: 0.4865 | Val RMSE_VA: 1.5500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 139/139 [00:51<00:00,  2.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 | Train Loss: 0.3082 | Val RMSE_VA: 1.2077\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 139/139 [00:51<00:00,  2.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 | Train Loss: 0.2325 | Val RMSE_VA: 1.1279\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 139/139 [00:51<00:00,  2.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 | Train Loss: 0.1931 | Val RMSE_VA: 1.1694\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 139/139 [00:50<00:00,  2.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6 | Train Loss: 0.1538 | Val RMSE_VA: 1.2285\n",
            "Early stopping triggered\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load(\"best_roberta_va.pt\"))\n",
        "model.eval()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BpxFf3XLcFbK",
        "outputId": "ff81b020-c950-45af-f512-305a84fc9b12"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RobertaForVA(\n",
              "  (roberta): RobertaModel(\n",
              "    (embeddings): RobertaEmbeddings(\n",
              "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
              "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
              "      (token_type_embeddings): Embedding(1, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): RobertaEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSdpaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): RobertaPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (regressor): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_preds, test_golds = [], []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_internal_loader:\n",
        "        input_ids = batch[\"input_ids\"].to(device)\n",
        "        attention_mask = batch[\"attention_mask\"].to(device)\n",
        "        labels = batch[\"labels\"].to(device)\n",
        "\n",
        "        preds = model(input_ids, attention_mask)\n",
        "        test_preds.append(preds.cpu().numpy())\n",
        "        test_golds.append(labels.cpu().numpy())\n",
        "\n",
        "test_preds = np.vstack(test_preds)\n",
        "test_golds = np.vstack(test_golds)\n",
        "\n",
        "print(\"=== INTERNAL TEST PERFORMANCE ===\")\n",
        "print(\"Official RMSE_VA:\", rmse_va(test_golds, test_preds))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7fCck0ozcKhT",
        "outputId": "83a6fe44-dfd1-4c51-d44b-a6cd7222277e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== INTERNAL TEST PERFORMANCE ===\n",
            "Official RMSE_VA: 1.0885552\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loader = DataLoader(\n",
        "    AspectVADataset(test_df, train=False),\n",
        "    batch_size=16\n",
        ")\n",
        "\n",
        "model.eval()\n",
        "outputs = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        input_ids = batch[\"input_ids\"].to(device)\n",
        "        attention_mask = batch[\"attention_mask\"].to(device)\n",
        "\n",
        "        preds = model(input_ids, attention_mask)\n",
        "        outputs.append(preds.cpu().numpy())\n",
        "\n",
        "outputs = np.vstack(outputs)\n",
        "outputs = np.clip(outputs, 1.0, 9.0)\n",
        "\n",
        "test_df[\"VA\"] = [f\"{v:.2f}#{a:.2f}\" for v, a in outputs]\n",
        "\n",
        "# ---------- WRITE JSONL (ONE OBJECT PER LINE) ----------\n",
        "output_path = \"pred_eng_restaurant.jsonl\"\n",
        "\n",
        "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    for rid in test_df[\"id\"].unique():   # preserves ID order\n",
        "        group = test_df[test_df[\"id\"] == rid]\n",
        "\n",
        "        record = {\n",
        "            \"ID\": rid,\n",
        "            \"Aspect_VA\": [\n",
        "                {\"Aspect\": row[\"aspect\"], \"VA\": row[\"VA\"]}\n",
        "                for _, row in group.iterrows()\n",
        "            ]\n",
        "        }\n",
        "\n",
        "        f.write(json.dumps(record, ensure_ascii=False) + \"\\n\")\n",
        "\n",
        "print(f\"{output_path} generated ✅\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zFztX4THcOFe",
        "outputId": "188502c8-9413-45a1-e056-2a84686b83a1"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pred_eng_restaurant.jsonl generated ✅\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"pred_eng_restaurant.jsonl\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "FaJxjCgKesh3",
        "outputId": "cc619df6-c368-4a2f-c574-1ce4cf042292"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_cb786943-9afc-45b2-bef9-edc2ca32a230\", \"pred_eng_restaurant.jsonl\", 116895)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}