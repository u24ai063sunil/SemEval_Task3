{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "c2riE5ccQexn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f99cd1fd-f0e1-4546-d3eb-467157009a75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/608.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m604.2/608.4 kB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m608.4/608.4 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q transformers torch scikit-learn tqdm emoji\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import re\n",
        "import unicodedata\n",
        "import emoji\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n"
      ],
      "metadata": {
        "id": "_ZNrB8Jlbat7"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN_PATH = \"/content/zho_restaurant_train_alltasks.jsonl\"\n",
        "TEST_PATH  = \"/content/zho_restaurant_test_task1.jsonl\"\n",
        "\n",
        "def load_jsonl(path):\n",
        "    data = []\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "        for line in f:\n",
        "            data.append(json.loads(line))\n",
        "    return data\n",
        "\n",
        "train_raw = load_jsonl(TRAIN_PATH)\n",
        "test_raw  = load_jsonl(TEST_PATH)\n",
        "\n",
        "print(\"Train reviews:\", len(train_raw))\n",
        "print(\"Test reviews :\", len(test_raw))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "whPSvwf3bgZr",
        "outputId": "9fda801c-6286-42db-8150-9ee8d6fecb8b"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train reviews: 6050\n",
            "Test reviews : 1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_text(text):\n",
        "    text = unicodedata.normalize(\"NFKC\", text)\n",
        "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
        "    return text\n",
        "\n",
        "def remove_urls_html(text):\n",
        "    text = re.sub(r\"http\\S+|www\\S+\", \"\", text)\n",
        "    text = re.sub(r\"<.*?>\", \"\", text)\n",
        "    return text\n",
        "\n",
        "def handle_emojis(text):\n",
        "    return emoji.demojize(text, delimiters=(\" \", \" \"))\n",
        "\n",
        "def clip_va(v, a):\n",
        "    v = min(max(v, 1.0), 9.0)\n",
        "    a = min(max(a, 1.0), 9.0)\n",
        "    return round(v, 2), round(a, 2)\n"
      ],
      "metadata": {
        "id": "_t4BKcf6bobO"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mark_aspect_zh(text, aspect):\n",
        "    if aspect in text:\n",
        "        return text.replace(aspect, f\"【{aspect}】\")\n",
        "    return text\n"
      ],
      "metadata": {
        "id": "RK9VSGT1zNL6"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_train(data):\n",
        "    rows = []\n",
        "    for item in data:\n",
        "        if \"Quadruplet\" not in item:\n",
        "            continue\n",
        "\n",
        "        text = normalize_text(item[\"Text\"])\n",
        "        text = remove_urls_html(text)\n",
        "        text = handle_emojis(text)\n",
        "\n",
        "        for quad in item[\"Quadruplet\"]:\n",
        "            aspect = quad[\"Aspect\"]\n",
        "            if aspect == \"NULL\":\n",
        "                continue\n",
        "\n",
        "            text_marked = mark_aspect_zh(text, aspect)\n",
        "\n",
        "            v, a = map(float, quad[\"VA\"].split(\"#\"))\n",
        "            v, a = clip_va(v, a)\n",
        "\n",
        "            rows.append({\n",
        "                \"text\": text_marked,\n",
        "                \"aspect\": aspect,\n",
        "                \"valence\": v,\n",
        "                \"arousal\": a\n",
        "            })\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "def preprocess_test(data):\n",
        "    rows = []\n",
        "    for item in data:\n",
        "        if \"Aspect\" not in item:\n",
        "            continue\n",
        "\n",
        "        text = normalize_text(item[\"Text\"])\n",
        "        text = remove_urls_html(text)\n",
        "        text = handle_emojis(text)\n",
        "\n",
        "        for asp in item[\"Aspect\"]:\n",
        "            text_marked = mark_aspect_zh(text, asp)\n",
        "\n",
        "            rows.append({\n",
        "                \"id\": item[\"ID\"],\n",
        "                \"text\": text_marked,\n",
        "                \"aspect\": asp\n",
        "            })\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "train_df = preprocess_train(train_raw)\n",
        "test_df  = preprocess_test(test_raw)\n",
        "\n",
        "print(\"Train aspect samples:\", len(train_df))\n",
        "print(\"Test aspect samples :\", len(test_df))\n",
        "\n",
        "train_df.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        },
        "id": "5Mw9Dz2DbrIA",
        "outputId": "2ce82e80-5fbc-4bf2-f414-c19ae1ba4b8e"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train aspect samples: 8354\n",
            "Test aspect samples : 1929\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               text aspect  valence  arousal\n",
              "0        【肉粿】沒有很焦脆。     肉粿     4.00     5.00\n",
              "1  【肉粿】每一塊都好脆好恰好喜歡。     肉粿     6.25     6.00\n",
              "2  【肉粿】每一塊都好脆好恰好喜歡。     肉粿     6.12     6.00\n",
              "3  【肉粿】每一塊都好脆好恰好喜歡。     肉粿     6.62     6.62\n",
              "4         【口感】有點微妙。     口感     4.75     4.75"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4b873310-1520-452f-a0fd-52ab33d48dda\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>aspect</th>\n",
              "      <th>valence</th>\n",
              "      <th>arousal</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>【肉粿】沒有很焦脆。</td>\n",
              "      <td>肉粿</td>\n",
              "      <td>4.00</td>\n",
              "      <td>5.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>【肉粿】每一塊都好脆好恰好喜歡。</td>\n",
              "      <td>肉粿</td>\n",
              "      <td>6.25</td>\n",
              "      <td>6.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>【肉粿】每一塊都好脆好恰好喜歡。</td>\n",
              "      <td>肉粿</td>\n",
              "      <td>6.12</td>\n",
              "      <td>6.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>【肉粿】每一塊都好脆好恰好喜歡。</td>\n",
              "      <td>肉粿</td>\n",
              "      <td>6.62</td>\n",
              "      <td>6.62</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>【口感】有點微妙。</td>\n",
              "      <td>口感</td>\n",
              "      <td>4.75</td>\n",
              "      <td>4.75</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4b873310-1520-452f-a0fd-52ab33d48dda')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4b873310-1520-452f-a0fd-52ab33d48dda button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4b873310-1520-452f-a0fd-52ab33d48dda');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_df",
              "summary": "{\n  \"name\": \"train_df\",\n  \"rows\": 8354,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7299,\n        \"samples\": [\n          \"\\u6539\\u9ede\\u7684\\u98df\\u7269\\u90fd\\u9084\\u4e0d\\u932f,\\u8d85\\u63a8\\u3010\\u9eb5\\u5305\\u3011\\u3002\",\n          \"\\u3010\\u6e6f\\u54c1\\u3011\\u5927\\u6982\\u662f\\u6574\\u684c\\u83dc\\u8272\\u7684\\u6557\\u7b46,\\u6cb9\\u81a9\\u5230\\u559d\\u4e00\\u53e3\\u5c31\\u4e0d\\u60f3\\u559d\\u3002\",\n          \"\\u3010\\u83dc\\u8272\\u54c1\\u8cea\\u3011\\u90fd\\u4e0d\\u6703\\u592a\\u5dee,\\u7279\\u5225\\u5927\\u63a8\\u9178\\u83dc\\u9b5a\\u8ddf\\u9d5d\\u4e09\\u5bf6\\u3002\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"aspect\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3432,\n        \"samples\": [\n          \"\\u97d3\\u5f0f\\u6dbc\\u9eb5\",\n          \"\\u9ebb\\u6cb9\\u9d28\\u8089\\u98ef\",\n          \"\\u81ea\\u52a9\\u5427\\u98df\\u6750\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"valence\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9908063081718526,\n        \"min\": 1.5,\n        \"max\": 8.25,\n        \"num_unique_values\": 109,\n        \"samples\": [\n          2.5,\n          6.1,\n          4.75\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"arousal\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.6488064615912896,\n        \"min\": 4.0,\n        \"max\": 8.25,\n        \"num_unique_values\": 72,\n        \"samples\": [\n          6.5,\n          4.25,\n          5.88\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df, temp_df = train_test_split(\n",
        "    train_df, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "val_df, test_internal_df = train_test_split(\n",
        "    temp_df, test_size=0.5, random_state=42\n",
        ")\n",
        "\n",
        "print(\"Train:\", len(train_df))\n",
        "print(\"Val  :\", len(val_df))\n",
        "print(\"Test :\", len(test_internal_df))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mQaCcqDfbt4i",
        "outputId": "0b6a1284-f0c7-4e1d-8ec2-ea16981806a3"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 6683\n",
            "Val  : 835\n",
            "Test : 836\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_NAME = \"hfl/chinese-roberta-wwm-ext\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "\n",
        "class AspectVADataset(Dataset):\n",
        "    def __init__(self, df, train=True):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.train = train\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "\n",
        "        enc = tokenizer(\n",
        "            row[\"text\"],\n",
        "            row[\"aspect\"],\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            max_length=128,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "\n",
        "        item = {\n",
        "            \"input_ids\": enc[\"input_ids\"].squeeze(0),\n",
        "            \"attention_mask\": enc[\"attention_mask\"].squeeze(0)\n",
        "        }\n",
        "\n",
        "        if self.train:\n",
        "            item[\"labels\"] = torch.tensor(\n",
        "                [row[\"valence\"], row[\"arousal\"]],\n",
        "                dtype=torch.float\n",
        "            )\n",
        "        return item\n",
        "\n"
      ],
      "metadata": {
        "id": "ne0q2qRRby8F"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(\n",
        "    AspectVADataset(train_df, train=True),\n",
        "    batch_size=16,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    AspectVADataset(val_df, train=True),\n",
        "    batch_size=16\n",
        ")\n",
        "\n",
        "test_internal_loader = DataLoader(\n",
        "    AspectVADataset(test_internal_df, train=True),\n",
        "    batch_size=16\n",
        ")\n"
      ],
      "metadata": {
        "id": "4UTeRzzib2Od"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RobertaForVA(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.roberta = AutoModel.from_pretrained(MODEL_NAME)\n",
        "        self.regressor = torch.nn.Linear(768, 2)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.roberta(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask\n",
        "        )\n",
        "        pooled = outputs.last_hidden_state[:, 0, :]\n",
        "        return self.regressor(pooled)\n"
      ],
      "metadata": {
        "id": "OgBZHQDab6cT"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = RobertaForVA().to(device)\n",
        "\n",
        "optimizer = torch.optim.AdamW(\n",
        "    model.parameters(),\n",
        "    lr=2e-5,\n",
        "    weight_decay=0.01\n",
        ")\n"
      ],
      "metadata": {
        "id": "TaM3epA_b9EO"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def rmse_va(y_true, y_pred):\n",
        "    squared_diff = (y_pred - y_true) ** 2\n",
        "    return np.sqrt(squared_diff.sum(axis=1).mean())\n"
      ],
      "metadata": {
        "id": "okwg7sDib_j4"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_val_rmse = float(\"inf\")\n",
        "patience = 2\n",
        "patience_counter = 0\n",
        "MAX_EPOCHS = 10\n",
        "\n",
        "for epoch in range(MAX_EPOCHS):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for batch in tqdm(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        input_ids = batch[\"input_ids\"].to(device)\n",
        "        attention_mask = batch[\"attention_mask\"].to(device)\n",
        "        labels = batch[\"labels\"].to(device)\n",
        "\n",
        "        preds = model(input_ids, attention_mask)\n",
        "        loss = torch.nn.functional.smooth_l1_loss(preds, labels)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    model.eval()\n",
        "    val_preds, val_golds = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "            input_ids = batch[\"input_ids\"].to(device)\n",
        "            attention_mask = batch[\"attention_mask\"].to(device)\n",
        "            labels = batch[\"labels\"].to(device)\n",
        "\n",
        "            preds = model(input_ids, attention_mask)\n",
        "            val_preds.append(preds.cpu().numpy())\n",
        "            val_golds.append(labels.cpu().numpy())\n",
        "\n",
        "    val_preds = np.vstack(val_preds)\n",
        "    val_golds = np.vstack(val_golds)\n",
        "\n",
        "    val_rmse = rmse_va(val_golds, val_preds)\n",
        "\n",
        "    print(f\"Epoch {epoch+1} | Train Loss: {total_loss/len(train_loader):.4f} | Val RMSE_VA: {val_rmse:.4f}\")\n",
        "\n",
        "    if val_rmse < best_val_rmse:\n",
        "        best_val_rmse = val_rmse\n",
        "        patience_counter = 0\n",
        "        torch.save(model.state_dict(), \"best_zh_roberta_va.pt\")\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "        if patience_counter >= patience:\n",
        "            print(\"Early stopping triggered\")\n",
        "            break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zhFGeQgVcCf2",
        "outputId": "fe1e21e0-713a-4a4f-d495-7e8ab708bc6c"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 418/418 [02:16<00:00,  3.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 | Train Loss: 0.2527 | Val RMSE_VA: 0.7989\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 418/418 [02:22<00:00,  2.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 | Train Loss: 0.0994 | Val RMSE_VA: 0.8013\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 418/418 [02:24<00:00,  2.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 | Train Loss: 0.0830 | Val RMSE_VA: 0.9215\n",
            "Early stopping triggered\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load(\"best_zh_roberta_va.pt\"))\n",
        "model.eval()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "id": "BpxFf3XLcFbK",
        "outputId": "d5ed6995-eb4a-42ec-cc00-155ad06963a7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1102205377.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"best_zh_roberta_va.pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_preds, test_golds = [], []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_internal_loader:\n",
        "        input_ids = batch[\"input_ids\"].to(device)\n",
        "        attention_mask = batch[\"attention_mask\"].to(device)\n",
        "        labels = batch[\"labels\"].to(device)\n",
        "\n",
        "        preds = model(input_ids, attention_mask)\n",
        "        test_preds.append(preds.cpu().numpy())\n",
        "        test_golds.append(labels.cpu().numpy())\n",
        "\n",
        "test_preds = np.vstack(test_preds)\n",
        "test_golds = np.vstack(test_golds)\n",
        "\n",
        "print(\"=== INTERNAL TEST PERFORMANCE ===\")\n",
        "print(\"Official RMSE_VA:\", rmse_va(test_golds, test_preds))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7fCck0ozcKhT",
        "outputId": "e80f37c6-277b-444b-c224-97f1fa6dceac"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== INTERNAL TEST PERFORMANCE ===\n",
            "Official RMSE_VA: 0.8975309\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loader = DataLoader(\n",
        "    AspectVADataset(test_df, train=False),\n",
        "    batch_size=16\n",
        ")\n",
        "\n",
        "outputs = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        input_ids = batch[\"input_ids\"].to(device)\n",
        "        attention_mask = batch[\"attention_mask\"].to(device)\n",
        "\n",
        "        preds = model(input_ids, attention_mask)\n",
        "        outputs.append(preds.cpu().numpy())\n",
        "\n",
        "outputs = np.vstack(outputs)\n",
        "outputs = np.clip(outputs, 1.0, 9.0)\n",
        "\n",
        "test_df = test_df.reset_index(drop=True)\n",
        "test_df[\"VA\"] = [f\"{v:.2f}#{a:.2f}\" for v, a in outputs]\n",
        "\n",
        "with open(\"pred_zho_laptop.jsonl\", \"w\", encoding=\"utf-8\") as f:\n",
        "    for rid in test_df[\"id\"].unique():\n",
        "        group = test_df[test_df[\"id\"] == rid]\n",
        "        record = {\n",
        "            \"ID\": rid,\n",
        "            \"Aspect_VA\": [\n",
        "                {\"Aspect\": row[\"aspect\"], \"VA\": row[\"VA\"]}\n",
        "                for _, row in group.iterrows()\n",
        "            ]\n",
        "        }\n",
        "        f.write(json.dumps(record, ensure_ascii=False) + \"\\n\")\n",
        "\n",
        "print(\"pred_zho_laptop.jsonl generated ✅\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zFztX4THcOFe",
        "outputId": "b682d9d9-9a27-4b68-9c70-86062ae2bc73"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pred_zho_laptop.jsonl generated ✅\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"pred_zho_laptop.jsonl\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "FaJxjCgKesh3",
        "outputId": "41e06881-0be7-495c-96c2-89222fbf02f9"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_c8cec1c6-4220-4212-8fef-206e7dead011\", \"pred_zho_laptop.jsonl\", 114051)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}