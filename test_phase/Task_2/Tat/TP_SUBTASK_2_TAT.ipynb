{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wXQcm8kFUC4m",
        "outputId": "ece16da9-86f3-449c-e88b-ce5ddbe0fea7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/43.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m608.4/608.4 kB\u001b[0m \u001b[31m44.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q transformers torch scikit-learn tqdm emoji seqeval\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fugashi ipadic unidic_lite"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_G-Fccu4Yc8",
        "outputId": "1a765089-ef02-4e04-d5bc-7cc11857eaf9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fugashi in /usr/local/lib/python3.12/dist-packages (1.5.2)\n",
            "Requirement already satisfied: ipadic in /usr/local/lib/python3.12/dist-packages (1.0.0)\n",
            "Collecting unidic_lite\n",
            "  Downloading unidic-lite-1.0.8.tar.gz (47.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.4/47.4 MB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: unidic_lite\n",
            "  Building wheel for unidic_lite (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for unidic_lite: filename=unidic_lite-1.0.8-py3-none-any.whl size=47658817 sha256=ab11e22df6eb506b9974fe918bbbb24cfdf6f7822c6429d0ecea7c2b331c3429\n",
            "  Stored in directory: /root/.cache/pip/wheels/5e/1f/0f/4d43887e5476d956fae828ee9b6687becd5544d68b51ed633d\n",
            "Successfully built unidic_lite\n",
            "Installing collected packages: unidic_lite\n",
            "Successfully installed unidic_lite-1.0.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "WE79epeKUT_8"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import re\n",
        "import unicodedata\n",
        "import emoji\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "kWuAii7JUVf_"
      },
      "outputs": [],
      "source": [
        "TRAIN_PATH = \"/content/tat_restaurant_train_alltasks.jsonl\"\n",
        "TEST_PATH  = \"/content/tat_restaurant_test_task2.jsonl\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FngePpwZUfpd",
        "outputId": "8c203574-4141-4f26-ac38-c4b1820a0df3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train reviews: 1240\n",
            "Test reviews : 630\n"
          ]
        }
      ],
      "source": [
        "def load_jsonl(path):\n",
        "    data = []\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "        for line in f:\n",
        "            data.append(json.loads(line))\n",
        "    return data\n",
        "\n",
        "train_raw = load_jsonl(TRAIN_PATH)\n",
        "test_raw  = load_jsonl(TEST_PATH)\n",
        "\n",
        "print(\"Train reviews:\", len(train_raw))\n",
        "print(\"Test reviews :\", len(test_raw))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {
        "id": "iUuXHFFBUykx"
      },
      "outputs": [],
      "source": [
        "def clean_text(text):\n",
        "    text = unicodedata.normalize(\"NFKC\", text)\n",
        "    text = re.sub(r\"http\\S+|www\\S+\", \"\", text)\n",
        "    text = re.sub(r\"<.*?>\", \"\", text)\n",
        "    text = emoji.demojize(text, delimiters=(\" \", \" \"))\n",
        "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %%\n",
        "MODEL_NAME = \"xlm-roberta-base\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "label2id = {\"O\":0, \"B-ASP\":1, \"I-ASP\":2, \"B-OPN\":3, \"I-OPN\":4}\n",
        "id2label = {v:k for k,v in label2id.items()}\n"
      ],
      "metadata": {
        "id": "WT0TIhRy4uOR"
      },
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "id": "9Uf5fi4tU1ty"
      },
      "outputs": [],
      "source": [
        "# %%\n",
        "def build_bio(tokens, aspects, opinions):\n",
        "    labels = [\"O\"] * len(tokens)\n",
        "\n",
        "    def mark(span, tag):\n",
        "        s = span.split()\n",
        "        for i in range(len(tokens) - len(s) + 1):\n",
        "            if tokens[i:i+len(s)] == s:\n",
        "                labels[i] = f\"B-{tag}\"\n",
        "                for j in range(1, len(s)):\n",
        "                    labels[i+j] = f\"I-{tag}\"\n",
        "\n",
        "    for a in aspects:\n",
        "        mark(a, \"ASP\")\n",
        "    for o in opinions:\n",
        "        mark(o, \"OPN\")\n",
        "\n",
        "    return labels\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_bio_token_aligned(text, aspects, opinions):\n",
        "    enc = tokenizer(\n",
        "        text,\n",
        "        return_offsets_mapping=True,\n",
        "        truncation=True,\n",
        "        max_length=128\n",
        "    )\n",
        "\n",
        "    offsets = enc[\"offset_mapping\"]\n",
        "    labels = [\"O\"] * len(offsets)\n",
        "\n",
        "    def mark(span, tag):\n",
        "        span = span.strip()\n",
        "        if not span:\n",
        "            return\n",
        "\n",
        "        for i, (s, e) in enumerate(offsets):\n",
        "            if s == e:\n",
        "                continue\n",
        "            token_text = text[s:e]\n",
        "            if token_text == span:\n",
        "                labels[i] = f\"B-{tag}\"\n",
        "            elif span.startswith(token_text):\n",
        "                labels[i] = f\"I-{tag}\"\n",
        "\n",
        "    for a in aspects:\n",
        "        mark(a, \"ASP\")\n",
        "    for o in opinions:\n",
        "        mark(o, \"OPN\")\n",
        "\n",
        "    return labels\n"
      ],
      "metadata": {
        "id": "e0-ooJNBdFwA"
      },
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uvmknagnU7-P",
        "outputId": "07f48bd8-145b-4f45-eaf8-d6af2e47fd52"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 992 Val: 248\n"
          ]
        }
      ],
      "source": [
        "# %%\n",
        "def preprocess_train(data):\n",
        "    rows = []\n",
        "    for it in data:\n",
        "        text = clean_text(it[\"Text\"])\n",
        "        aspects, opinions = [], []\n",
        "\n",
        "        for q in it[\"Quadruplet\"]:\n",
        "            if q[\"Aspect\"] != \"NULL\":\n",
        "                aspects.append(q[\"Aspect\"])\n",
        "                opinions.append(q[\"Opinion\"])\n",
        "\n",
        "        tokens = text.split()\n",
        "        if not tokens:\n",
        "            continue\n",
        "        labels = build_bio_token_aligned(text, aspects, opinions)\n",
        "        if len(labels) != len(tokens):\n",
        "            labels = [\"O\"] * len(tokens)\n",
        "\n",
        "        rows.append({\"text\": text, \"labels\": labels})\n",
        "\n",
        "    return rows\n",
        "\n",
        "train_data = preprocess_train(train_raw)\n",
        "train_data, val_data = train_test_split(train_data, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"Train:\", len(train_data), \"Val:\", len(val_data))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {
        "id": "mMDPvf5aU_E3"
      },
      "outputs": [],
      "source": [
        "# %%\n",
        "test_data = [{\"id\": x[\"ID\"], \"text\": clean_text(x[\"Text\"])} for x in test_raw]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {
        "id": "QIRq3lnOVHZz"
      },
      "outputs": [],
      "source": [
        "# %%\n",
        "class DimASTEDataset(Dataset):\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        it = self.data[idx]\n",
        "        enc = tokenizer(\n",
        "            it[\"text\"],\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            max_length=128,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "        labels = [label2id[l] for l in it[\"labels\"]] + [0]*(128-len(it[\"labels\"]))\n",
        "\n",
        "        return {\n",
        "            \"input_ids\": enc[\"input_ids\"].squeeze(0),\n",
        "            \"attention_mask\": enc[\"attention_mask\"].squeeze(0),\n",
        "            \"labels\": torch.tensor(labels[:128])\n",
        "        }\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %%\n",
        "class DimASTEModel(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.encoder = AutoModel.from_pretrained(MODEL_NAME)\n",
        "        self.classifier = torch.nn.Linear(768, len(label2id))\n",
        "\n",
        "    def forward(self, ids, mask):\n",
        "        return self.classifier(self.encoder(ids, mask).last_hidden_state)\n"
      ],
      "metadata": {
        "id": "tqEQqYXCCmUN"
      },
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %%\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = DimASTEModel().to(device)\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
        "class_weights = torch.tensor([0.02,1.5,1.5,1.5,1.5], device=device)\n",
        "\n",
        "loader = DataLoader(DimASTEDataset(train_data), batch_size=8, shuffle=True)\n",
        "\n",
        "for e in range(5):\n",
        "    model.train()\n",
        "    total = 0\n",
        "    for b in tqdm(loader):\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(b[\"input_ids\"].to(device), b[\"attention_mask\"].to(device))\n",
        "        loss = torch.nn.functional.cross_entropy(\n",
        "            logits.view(-1, len(label2id)),\n",
        "            b[\"labels\"].to(device).view(-1),\n",
        "            weight=class_weights\n",
        "        )\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total += loss.item()\n",
        "    print(f\"BIO Epoch {e+1} | Loss {total/len(loader):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_CZZLpKDCoh7",
        "outputId": "9b9ae39e-cac2-4b74-a9f3-0cff9e20ab42"
      },
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 124/124 [00:34<00:00,  3.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BIO Epoch 1 | Loss 0.0627\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 124/124 [00:33<00:00,  3.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BIO Epoch 2 | Loss 0.0004\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 124/124 [00:33<00:00,  3.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BIO Epoch 3 | Loss 0.0002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 124/124 [00:33<00:00,  3.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BIO Epoch 4 | Loss 0.0002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 124/124 [00:33<00:00,  3.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BIO Epoch 5 | Loss 0.0001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %%\n",
        "def decode_with_smoothing(probs, b_th, i_th):\n",
        "    labels = []\n",
        "    prev = \"O\"\n",
        "    for p in probs:\n",
        "        if p[label2id[\"B-ASP\"]] > b_th:\n",
        "            lab = \"B-ASP\"\n",
        "        elif p[label2id[\"B-OPN\"]] > b_th:\n",
        "            lab = \"B-OPN\"\n",
        "        elif prev.startswith(\"B\") and p[label2id[\"I-\"+prev[2:]]] > i_th:\n",
        "            lab = \"I-\"+prev[2:]\n",
        "        else:\n",
        "            lab = \"O\"\n",
        "        labels.append(lab)\n",
        "        prev = lab\n",
        "    return labels\n"
      ],
      "metadata": {
        "id": "ziWkgFFCCoOL"
      },
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %%\n",
        "import string\n",
        "def normalize_tt_span(s):\n",
        "    s = s.lower().strip()\n",
        "    s = re.sub(r\"\\s+\", \" \", s)\n",
        "    s = s.strip(string.punctuation + \"«»“”„\")\n",
        "    return s\n",
        "\n",
        "def valid_span(s):\n",
        "    if not s:\n",
        "        return False\n",
        "    if len(s) < 3:\n",
        "        return False\n",
        "    if not any(c.isalpha() for c in s):\n",
        "        return False\n",
        "    return True\n"
      ],
      "metadata": {
        "id": "3VeuP4hJQiop"
      },
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %%\n",
        "def extract_triplets_token_aligned(text, probs, b_th, i_th):\n",
        "    enc = tokenizer(\n",
        "        text,\n",
        "        return_offsets_mapping=True,\n",
        "        truncation=True,\n",
        "        max_length=128,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "\n",
        "    offsets = enc[\"offset_mapping\"][0].tolist()\n",
        "    labels = decode_with_smoothing(probs, b_th, i_th)\n",
        "\n",
        "    aspects, opinions = [], []\n",
        "    cur_text, cur_type, last_end = \"\", None, None\n",
        "\n",
        "    for lab, (s, e) in zip(labels, offsets):\n",
        "        if s == e:\n",
        "            continue\n",
        "\n",
        "        tok = text[s:e]\n",
        "\n",
        "        if lab.startswith(\"B-\"):\n",
        "            if cur_text:\n",
        "                (aspects if cur_type==\"ASP\" else opinions).append(cur_text.strip())\n",
        "            cur_text, cur_type, last_end = tok, lab[2:], e\n",
        "\n",
        "        elif lab.startswith(\"I-\") and cur_type == lab[2:]:\n",
        "            cur_text += tok if last_end == s else \" \" + tok\n",
        "            last_end = e\n",
        "\n",
        "        else:\n",
        "            if cur_text:\n",
        "                (aspects if cur_type==\"ASP\" else opinions).append(cur_text.strip())\n",
        "            cur_text, cur_type, last_end = \"\", None, None\n",
        "\n",
        "    if cur_text:\n",
        "        (aspects if cur_type==\"ASP\" else opinions).append(cur_text.strip())\n",
        "\n",
        "    aspects  = [a for a in aspects  if valid_span(a)]\n",
        "    opinions = [o for o in opinions if valid_span(o)]\n",
        "\n",
        "    pairs = []\n",
        "    for o in opinions:\n",
        "        o_pos = text.find(o)\n",
        "        if o_pos == -1:\n",
        "            continue\n",
        "\n",
        "        best_a, best_d = None, 1e9\n",
        "        for a in aspects:\n",
        "            a_pos = text.find(a)\n",
        "            if a_pos == -1:\n",
        "                continue\n",
        "            d = abs(o_pos - a_pos)\n",
        "            if d < best_d:\n",
        "                best_d, best_a = d, a\n",
        "\n",
        "        if best_a:\n",
        "            pairs.append({\n",
        "                \"Aspect\": normalize_tt_span(best_a),\n",
        "                \"Opinion\": normalize_tt_span(o)\n",
        "            })\n",
        "\n",
        "    return pairs\n"
      ],
      "metadata": {
        "id": "-BHuYEp7Cn73"
      },
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %%\n",
        "class AspectVAModel(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.encoder = AutoModel.from_pretrained(MODEL_NAME)\n",
        "        self.regressor = torch.nn.Linear(768, 2)\n",
        "\n",
        "    def forward(self, ids, mask):\n",
        "        pooled = self.encoder(ids, mask).last_hidden_state[:,0]\n",
        "        return self.regressor(pooled)\n"
      ],
      "metadata": {
        "id": "SMk0ldoaC9XL"
      },
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %%\n",
        "def preprocess_va(data):\n",
        "    rows = []\n",
        "    for it in data:\n",
        "        text = clean_text(it[\"Text\"])\n",
        "        for q in it[\"Quadruplet\"]:\n",
        "            if q[\"Aspect\"] != \"NULL\":\n",
        "                v,a = map(float, q[\"VA\"].split(\"#\"))\n",
        "                rows.append({\n",
        "                    \"text\": f\"<ASP>{q['Aspect']}</ASP> {text}\",\n",
        "                    \"va\": torch.tensor([v,a], dtype=torch.float)\n",
        "                })\n",
        "    return rows\n",
        "\n",
        "va_data = preprocess_va(train_raw)\n",
        "\n",
        "va_model = AspectVAModel().to(device)\n",
        "va_opt = torch.optim.AdamW(va_model.parameters(), lr=2e-5)\n",
        "\n",
        "for e in range(3):\n",
        "    va_model.train()\n",
        "    for row in tqdm(va_data):\n",
        "        enc = tokenizer(row[\"text\"], return_tensors=\"pt\", truncation=True)\n",
        "        pred = va_model(enc[\"input_ids\"].to(device), enc[\"attention_mask\"].to(device))\n",
        "        loss = torch.nn.functional.smooth_l1_loss(pred, row[\"va\"].to(device))\n",
        "        va_opt.zero_grad()\n",
        "        loss.backward()\n",
        "        va_opt.step()\n",
        "    print(f\"VA Epoch {e+1} done\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1h0CnLSNDBIr",
        "outputId": "76a4b114-2281-485f-ad9c-b1dcd29543b3"
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/2487 [00:00<?, ?it/s]/tmp/ipython-input-3846665480.py:25: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([1, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  loss = torch.nn.functional.smooth_l1_loss(pred, row[\"va\"].to(device))\n",
            "100%|██████████| 2487/2487 [05:09<00:00,  8.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VA Epoch 1 done\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2487/2487 [05:09<00:00,  8.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VA Epoch 2 done\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2487/2487 [05:09<00:00,  8.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VA Epoch 3 done\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %%\n",
        "model.eval(); va_model.eval()\n",
        "\n",
        "with open(\"pred_tat_restaurant.jsonl\", \"w\", encoding=\"utf-8\") as f:\n",
        "    with torch.no_grad():\n",
        "        for it in test_data:\n",
        "            enc = tokenizer(it[\"text\"], return_tensors=\"pt\", truncation=True)\n",
        "            probs = torch.softmax(\n",
        "                model(enc[\"input_ids\"].to(device), enc[\"attention_mask\"].to(device))[0],\n",
        "                dim=-1\n",
        "            )\n",
        "\n",
        "            trips = extract_triplets_token_aligned(it[\"text\"], probs, 0.15, 0.10)\n",
        "\n",
        "            out = []\n",
        "            for t in trips:\n",
        "                enc2 = tokenizer(\n",
        "                    f\"<ASP>{t['Aspect']}</ASP> {it['text']}\",\n",
        "                    return_tensors=\"pt\", truncation=True\n",
        "                )\n",
        "                va = va_model(enc2[\"input_ids\"].to(device), enc2[\"attention_mask\"].to(device))[0].cpu().numpy()\n",
        "                va = np.clip(va, 1.5, 8.5)\n",
        "\n",
        "                out.append({\n",
        "                    \"Aspect\": t[\"Aspect\"],\n",
        "                    \"Opinion\": t[\"Opinion\"],\n",
        "                    \"VA\": f\"{va[0]:.2f}#{va[1]:.2f}\"\n",
        "                })\n",
        "\n",
        "            f.write(json.dumps({\"ID\": it[\"id\"], \"Triplet\": out}, ensure_ascii=False) + \"\\n\")\n",
        "\n",
        "print(\"pred_tat_restaurant.jsonl generated ✅\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HgdlUNK0NX21",
        "outputId": "8b269c50-455f-4a48-98d7-008355345093"
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pred_tat_restaurant.jsonl generated ✅\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DEBUG: BIO label distribution\n",
        "from collections import Counter\n",
        "\n",
        "cnt = Counter()\n",
        "for x in train_data[:200]:\n",
        "    cnt.update(x[\"labels\"])\n",
        "\n",
        "print(cnt)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yX1s3kLEfE4Q",
        "outputId": "974f0ee2-90c6-421e-e63b-61f03076c4f7"
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({'O': 2552})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %% [OFFICIAL cF1 EVALUATION — UKRAINIAN]\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# -------------------------\n",
        "# Official metric helpers\n",
        "# -------------------------\n",
        "D_MAX = 128.0\n",
        "\n",
        "def va_distance(pred_va, gold_va):\n",
        "    return ((pred_va[0]-gold_va[0])**2 + (pred_va[1]-gold_va[1])**2) / D_MAX\n",
        "\n",
        "def ctp(pred_va, gold_va):\n",
        "    return max(0.0, 1.0 - va_distance(pred_va, gold_va))\n",
        "\n",
        "# -------------------------\n",
        "# Build GOLD triplets\n",
        "# -------------------------\n",
        "gold_triplets = {}\n",
        "\n",
        "for item in train_raw:\n",
        "    text = clean_text(item[\"Text\"])\n",
        "    trips = []\n",
        "\n",
        "    for q in item[\"Quadruplet\"]:\n",
        "        if q[\"Aspect\"] == \"NULL\":\n",
        "            continue\n",
        "        v, a = map(float, q[\"VA\"].split(\"#\"))\n",
        "        trips.append({\n",
        "            \"Aspect\": normalize_tt_span(q[\"Aspect\"]),\n",
        "            \"Opinion\": normalize_tt_span(q[\"Opinion\"]),\n",
        "            \"VA\": np.array([v, a])\n",
        "        })\n",
        "\n",
        "    gold_triplets[text] = trips\n",
        "\n",
        "# -------------------------\n",
        "# Predict triplets on VAL\n",
        "# -------------------------\n",
        "def predict_triplets_val(val_data):\n",
        "    preds = {}\n",
        "    model.eval()\n",
        "    va_model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for item in val_data:\n",
        "            text = item[\"text\"]\n",
        "\n",
        "            enc = tokenizer(text, return_tensors=\"pt\", truncation=True)\n",
        "            probs = torch.softmax(\n",
        "                model(\n",
        "                    enc[\"input_ids\"].to(device),\n",
        "                    enc[\"attention_mask\"].to(device)\n",
        "                )[0],\n",
        "                dim=-1\n",
        "            )\n",
        "\n",
        "            triplets = extract_triplets_token_aligned(\n",
        "                text,\n",
        "                probs,\n",
        "                b_th=0.15,\n",
        "                i_th=0.10\n",
        "            )\n",
        "\n",
        "            out = []\n",
        "            for t in triplets:\n",
        "                enc2 = tokenizer(\n",
        "                    f\"<ASP>{t['Aspect']}</ASP> {text}\",\n",
        "                    return_tensors=\"pt\",\n",
        "                    truncation=True\n",
        "                )\n",
        "                va = va_model(\n",
        "                    enc2[\"input_ids\"].to(device),\n",
        "                    enc2[\"attention_mask\"].to(device)\n",
        "                )[0].cpu().numpy()\n",
        "\n",
        "                out.append({\n",
        "                    \"Aspect\": t[\"Aspect\"],\n",
        "                    \"Opinion\": t[\"Opinion\"],\n",
        "                    \"VA\": va\n",
        "                })\n",
        "\n",
        "            preds[text] = out\n",
        "\n",
        "    return preds\n",
        "\n",
        "pred_triplets = predict_triplets_val(val_data)\n",
        "\n",
        "# -------------------------\n",
        "# Compute official cF1\n",
        "# -------------------------\n",
        "def compute_cF1(preds, golds):\n",
        "    ctp_sum = 0.0\n",
        "    pred_count = 0\n",
        "    gold_count = 0\n",
        "\n",
        "    for text in golds:\n",
        "        gold_trips = golds[text]\n",
        "        pred_trips = preds.get(text, [])\n",
        "\n",
        "        gold_count += len(gold_trips)\n",
        "        pred_count += len(pred_trips)\n",
        "\n",
        "        used = set()\n",
        "        for p in pred_trips:\n",
        "            for i, g in enumerate(gold_trips):\n",
        "                if i in used:\n",
        "                    continue\n",
        "                if p[\"Aspect\"] == g[\"Aspect\"] and p[\"Opinion\"] == g[\"Opinion\"]:\n",
        "                    ctp_sum += ctp(p[\"VA\"], g[\"VA\"])\n",
        "                    used.add(i)\n",
        "                    break\n",
        "\n",
        "    if pred_count == 0 or gold_count == 0:\n",
        "        return 0.0, 0.0, 0.0\n",
        "\n",
        "    cP = ctp_sum / pred_count\n",
        "    cR = ctp_sum / gold_count\n",
        "    cF1 = 2 * cP * cR / (cP + cR) if (cP + cR) > 0 else 0.0\n",
        "\n",
        "    return cP, cR, cF1\n",
        "\n",
        "# -------------------------\n",
        "# Run evaluation\n",
        "# -------------------------\n",
        "cP, cR, cF1 = compute_cF1(pred_triplets, gold_triplets)\n",
        "\n",
        "print(\"=== OFFICIAL Subtask-2 Validation (cF1) — UKRAINIAN ===\")\n",
        "print(f\"cPrecision : {cP:.4f}\")\n",
        "print(f\"cRecall    : {cR:.4f}\")\n",
        "print(f\"cF1        : {cF1:.4f}\")\n",
        "\n",
        "# -------------------------\n",
        "# Coverage diagnostics\n",
        "# -------------------------\n",
        "total_pred = sum(len(v) for v in pred_triplets.values())\n",
        "total_gold = sum(len(v) for v in gold_triplets.values())\n",
        "\n",
        "print(\"\\nTriplet coverage:\")\n",
        "print(\"Predicted triplets:\", total_pred)\n",
        "print(\"Gold triplets     :\", total_gold)\n",
        "print(\"Recall ceiling    :\", total_pred / max(1, total_gold))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2pS3EG2eDdPg",
        "outputId": "6e011ca1-ef71-4902-eef0-9825c1813c38"
      },
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== OFFICIAL Subtask-2 Validation (cF1) — UKRAINIAN ===\n",
            "cPrecision : 0.0000\n",
            "cRecall    : 0.0000\n",
            "cF1        : 0.0000\n",
            "\n",
            "Triplet coverage:\n",
            "Predicted triplets: 0\n",
            "Gold triplets     : 2487\n",
            "Recall ceiling    : 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DEBUG: check predicted BIO labels\n",
        "enc = tokenizer(val_data[0][\"text\"], return_tensors=\"pt\", truncation=True)\n",
        "probs = torch.softmax(\n",
        "    model(enc[\"input_ids\"].to(device), enc[\"attention_mask\"].to(device))[0],\n",
        "    dim=-1\n",
        ")\n",
        "\n",
        "pred_labels = decode_with_smoothing(probs, 0.15, 0.10)\n",
        "print(set(pred_labels))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "duzltMZDg0eJ",
        "outputId": "a0eb198b-3e84-4c87-9fb8-4c9cb90e2df4"
      },
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'O'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "BcGXpg7dg1iW",
        "outputId": "4d5dd234-600d-4a97-d462-cc6eb54c0fdf"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_d384484c-c641-442a-afae-7099d2b1c29d\", \"pred_tat_restaurant.jsonl\", 21896)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.download(\"pred_tat_restaurant.jsonl\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AnYHGTi4RpTI"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}